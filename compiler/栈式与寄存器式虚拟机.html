<div class="RichContent RichContent--unescapable"><span><div class="RichContent-inner"><span class="RichText ztext CopyrightRichText-richText css-yvdm7v" options="[object Object]" itemprop="text"><p data-first-child="" data-pid="6zOKFzZO">前面有回答提到了俺的老文：</p><a href="https://link.zhihu.com/?target=http%3A//rednaxelafx.iteye.com/blog/492667" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">虚拟机随谈（一）：解释器，树遍历解释器，基于栈与基于寄存器，大杂烩</a><br><p data-pid="WFghhAkB">俺就王婆卖瓜自己也发一次吧。</p><p data-pid="r5sq76LE">备注：本回答全文原创，未经许可不允许转载。特别不允许<span><a data-za-not-track-link="true" href="https://www.zhihu.com/search?q=%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A64575683%7D" target="_blank" class="css-pgtd2j">清华大学出版社<svg width="10px" height="10px" viewBox="0 0 15 15" class="css-1dvsrp"><path d="M10.89 9.477l3.06 3.059a1 1 0 0 1-1.414 1.414l-3.06-3.06a6 6 0 1 1 1.414-1.414zM6 10a4 4 0 1 0 0-8 4 4 0 0 0 0 8z" fill="currentColor"></path></svg></a></span>以任何形式转载本文。此备注背景请参考：</p><a href="https://link.zhihu.com/?target=http%3A//www.douban.com/doulist/42057979/" class=" external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043"><span class="invisible">http://www.</span><span class="visible">douban.com/doulist/4205</span><span class="invisible">7979/</span><span class="ellipsis"></span></a><br><br><p data-pid="0PygjQcB">===========================================</p><p data-pid="tLkEru48">太长不读（TL;DR）版定性分析：</p><p data-pid="HLAUNrIr">对于解释器来说，解释器开销主要来自解释器循环（fetch-decode/dispatch-execute循环）中的fetch与decode/dispatch，反而真正用于执行程序逻辑的execute部分并不是大头。每条指令都要经历一轮FDX循环。因而减少指令条数可以导致F与D的开销减少，于是就提升了解释器速度。</p><p data-pid="mn__7zon">基于栈与基于寄存器的指令集，用在解释器里，笼统说有以下对比：</p><ul><li data-pid="RGsUgjnk">从源码生成代码的难度：基于栈 &lt; 基于寄存器，不过差别不是特别大</li><li data-pid="XnZk61pD">表示同样程序逻辑的代码大小（code size）：基于栈 &lt; 基于寄存器</li><li data-pid="Ul55ik6m">表示同样程序逻辑的指令条数（instruction count）：基于栈 &gt; 基于寄存器</li><li data-pid="FpTr9l_a">简易实现中数据移动次数（data movement count）：基于栈 &gt; 基于寄存器；不过值得一提的是实现时通过栈顶缓存（top-of-stack caching）可以大幅降低基于栈的解释器的数据移动开销，可以让这部分开销跟基于寄存器的在同等水平。请参考另一个回答：<a href="http://www.zhihu.com/question/29355187/answer/51935409" class="internal" data-za-detail-view-id="1043">寄存器分配问题？ - RednaxelaFX 的回答</a></li><li data-pid="3sjCk_wO">采用同等优化程度的解释器速度：基于栈 &lt; 基于寄存器</li><li data-pid="Y0fPXG56">交由同等优化程度的JIT编译器编译后生成的代码速度：基于栈 === 基于寄存器</li></ul><p data-pid="QUIgp1v8">因而，笼统说可以有以下结论：要追求</p><ul><li data-pid="7tRPS9Hw">尽量实现简单：选择基于栈</li><li data-pid="v86CD6JO">传输代码的大小尽量小：选择基于栈</li><li data-pid="MwjgEcAA">纯解释执行的解释器的速度：选择基于寄存器</li><li data-pid="F9rgOvWo">带有JIT编译器的执行引擎的速度：随便，两者一样；对简易JIT编译器而言基于栈的指令集可能反而更便于生成更快的代码，而对比较优化的JIT编译器而言输入是基于栈还是基于寄存器都无所谓，经过<span><a data-za-not-track-link="true" href="https://www.zhihu.com/search?q=parse&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A64575683%7D" target="_blank" class="css-pgtd2j">parse<svg width="10px" height="10px" viewBox="0 0 15 15" class="css-1dvsrp"><path d="M10.89 9.477l3.06 3.059a1 1 0 0 1-1.414 1.414l-3.06-3.06a6 6 0 1 1 1.414-1.414zM6 10a4 4 0 1 0 0-8 4 4 0 0 0 0 8z" fill="currentColor"></path></svg></a></span>之后就变得完全一样了。</li></ul><p data-pid="kod8tr0q">===========================================</p><p data-pid="2CCTrRMR"><b>JVM的选择</b></p><p data-pid="Z4y1tSXT">JVM当初设计的时候非常重视代码传输和存储的开销，因为假定的应用场景是诸如手持设备（PDA）、机顶盒之类的嵌入式应用，所以要代码尽量小；外加基于栈的实现更简单（无论是在源码编译器的一侧还是在虚拟机的一侧），而且主要设计者James Gosling的个人经验上也对这种做法非常熟悉（例如他之前实现过PostScript的虚拟机，也是基于栈的指令集），所以就选择了基于栈。</p><p data-pid="6lcowsd3">回头看，这个决定也还算OK，可惜的是基于栈的设计并没有让Java的代码传输大小减小多少。</p><p data-pid="i96cWMEx">这是因为：Java代码是以Class文件为单位来传输与存储的。Java从设计之初就<b>非要</b>支持分离编译（separate compilation）与按需动态类加载（on-demand dynamic class loading），导致Java的Class文件必须独立的（self-contained）——每个Class文件必须自己携带自己的常量池，其主要信息是字符串与若干其它常量的值，以及用于符号链接的符号引用信息（symbolic reference）。</p><p data-pid="O9X--HFW">如果大家关注过Class文件的内容的话，会知道其实通常Class文件里表示程序逻辑的代码部分——“<span><a data-za-not-track-link="true" href="https://www.zhihu.com/search?q=%E5%AD%97%E8%8A%82%E7%A0%81&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A64575683%7D" target="_blank" class="css-pgtd2j">字节码<svg width="10px" height="10px" viewBox="0 0 15 15" class="css-1dvsrp"><path d="M10.89 9.477l3.06 3.059a1 1 0 0 1-1.414 1.414l-3.06-3.06a6 6 0 1 1 1.414-1.414zM6 10a4 4 0 1 0 0-8 4 4 0 0 0 0 8z" fill="currentColor"></path></svg></a></span>”——只占Class文件大小的小头；而大头都被常量池占了。而且多个Class文件的常量池内容之间常常有重叠，所以当程序涉及多个Class文件时，就容易有冗余信息，不利于减少传输/存储代码的大小。</p><p data-pid="_4W1hxVH">大家或许还记得Google在Google I/O 2008的</p><a href="https://link.zhihu.com/?target=https%3A//sites.google.com/site/io/dalvik-vm-internals" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">Dalvik VM Internals</a><p data-pid="-EooWRZs">演讲里，Dan得意的介绍到Dalvik的Dex格式在未压缩的情况下都比压缩了的JAR文件还小么？</p><p data-pid="DFcE79MT">（下面数据引用自演示稿第22页）</p><blockquote data-pid="Z5o_OQrC">common system libraries<br> (U) 21445320 — 100%<br> (J) 10662048 — 50%<br> (D) 10311972 — 48%<br><br>web browser app<br> (U) 470312 — 100%<br> (J) 232065 — 49%<br> (D) 209248 — 44%<br><br> alarm clock app<br> (U) 119200 — 100%<br> (J) 61658 — 52%<br> (D) 53020 — 44%<br><br>(U) uncompressed jar file<br>(J) compressed jar file<br>(D) uncompressed dex file</blockquote><p data-pid="qhFLpFZ-">Dan准确的介绍了Dex体积更小的原因：一个Dex相当于一个或多个JAR包，里面可以包含多个Class文件对应的内容。一个Dex文件里的所有Class都共享同一个常量池，因而不会像Class文件那样在多个常量池之间有冗余。这样Dex文件就等同于在<span><a data-za-not-track-link="true" href="https://www.zhihu.com/search?q=%E5%85%83%E6%95%B0%E6%8D%AE&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A64575683%7D" target="_blank" class="css-pgtd2j">元数据<svg width="10px" height="10px" viewBox="0 0 15 15" class="css-1dvsrp"><path d="M10.89 9.477l3.06 3.059a1 1 0 0 1-1.414 1.414l-3.06-3.06a6 6 0 1 1 1.414-1.414zM6 10a4 4 0 1 0 0-8 4 4 0 0 0 0 8z" fill="currentColor"></path></svg></a></span>层面上对JAR文件做了压缩，所以前者比后者更小。</p><p data-pid="wM4AXHrn">但是很明显后来有不少群众不明就里，以为Dalvik的Dex文件更小是跟基于寄存器的选择相关的——其实正好相反，在字节码部分，Dalvik的字节码其实比JVM的字节码更大。只要仔细读了同一个演示稿就会看到</p><p data-pid="LVAXDViT">（第37页）</p><blockquote data-pid="1rUBXfbN">The Register Machine<br><ul><li data-pid="ODzAOJIG">30% fewer instructions<br></li><li data-pid="HQ1Aus7O">35% fewer code units<br></li><li data-pid="JkPQlAjg"><b>35% <i>more</i> bytes in the instruction stream</b><br></li><ul><li data-pid="OjkKk6O7">but we get to consume two at a time</li></ul></ul></blockquote><p data-pid="1qnqbxsP">而其实Java世界里早就发现了这个问题，并且有一个传输/存储格式跟Dex文件应用了类似的压缩思路：</p><a href="https://link.zhihu.com/?target=http%3A//docs.oracle.com/javase/7/docs/technotes/tools/share/pack200.html" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">pack200</a><p data-pid="_Kl2Gp8g">格式。它也是把JAR包里的所有Class文件的常量池汇总为一个，以此压缩掉其中的冗余。以pack200格式打包的Java应用就不会比用Dex格式打包大了。</p><p data-pid="49zcLyHr">之前在Oracle的HotSpot JVM组工作时，跟同事们讨论一些与此相关的话题，大家的共识是如果JVM的指令集是在20年后的今天设计的话，很有可能也会跟现在的潮流相似，基于寄存器。不过就算保持现在这样用基于栈的指令集也挺好。</p><p data-pid="A5vmIO1-">目前Class文件/JAR文件的真正让大家头疼的问题并不是基于栈还是基于寄存器的设计，而是别的地方，例如：</p><p data-pid="mTYENHWP">Class文件方面：</p><ul><li data-pid="anzq6ib1">各种人为的大小限制都跟不上时代了，例如每个方法的字节码最多65535字节；</li><li data-pid="VwO_nS43">要生成StackMapTable太闹心；</li><li data-pid="gLR7U8xS">常量池的组织方式不便于直接从文件映射到内存然后高效执行；可以有更高效的组织方式。</li></ul><p data-pid="AJNDCGrV">JAR文件方面：</p><ul><li data-pid="e4Vithu7">如前文提的，多个Class文件之间的常量池冗余；</li><li data-pid="K7LfKCaB">缺少带有强语义的描述模块的信息；</li><li data-pid="X0z_WX75">等等…</li></ul><p data-pid="cU8yKMES">一切都有待未来版本的Java继续改进。</p><p data-pid="BZqNGqg6">===========================================</p><p data-pid="HqNVS5Pi"><b>Lua的选择</b></p><p data-pid="2vj_RdGj">官方版Lua的设计可以从经典文章 </p><a href="https://link.zhihu.com/?target=http%3A//www.lua.org/doc/jucs05.pdf" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">The Implementation of Lua 5.0</a><p data-pid="Hv9F4_HA"> 一窥究竟。</p><p data-pid="_wIBbKSq">它提到：</p><blockquote data-pid="FnndgjYl">For ten years (since 1993, when Lua was first released), Lua used a stack-based virtual machine, in various <span><a data-za-not-track-link="true" href="https://www.zhihu.com/search?q=incarnations&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A64575683%7D" target="_blank" class="css-pgtd2j">incarnations<svg width="10px" height="10px" viewBox="0 0 15 15" class="css-1dvsrp"><path d="M10.89 9.477l3.06 3.059a1 1 0 0 1-1.414 1.414l-3.06-3.06a6 6 0 1 1 1.414-1.414zM6 10a4 4 0 1 0 0-8 4 4 0 0 0 0 8z" fill="currentColor"></path></svg></a></span>. Since 2003, with the release of Lua 5.0, Lua uses a register-based virtual machine.<br></blockquote><p data-pid="b9vl4V7T">也就是说Lua 5.0之前的Lua其实是用基于栈的指令集，到5.0才改为用基于寄存器的。</p><p data-pid="JVttWPoe">接下来：</p><blockquote data-pid="eSWdz8S6">Register-based code avoids several “push” and “pop” instructions that stack-based code needs to move values around the stack. Those instructions are particularly expensive in Lua, because they involve the copy of a tagged value, as discussed in Section 3. <b>So, the register architecture both avoids excessive copying </b><b>of values and reduces the total number of instructions per function.</b> Davis et al. [6] argue in defense of register-based virtual machines and provide hard data on the improvement of Java bytecode. Some authors also defend register-based virtual machines based on their suitability for on-the-fly compilation (see [24], for instance).</blockquote><p data-pid="FJVHHvn_">所以Lua 5.0开始改为选用基于寄存器的指令集设计，主要是出于 (1) 减少数据移动次数，降低由数据移动带来的拷贝开销，和 (2) 减少虚拟指令条数 这两点考虑。</p><p data-pid="kPtrW3as">从纯解释器的角度看，这两点考虑是非常合理的。</p><p data-pid="CpWOGVs7">不过如果官方版Lua有JIT编译器的话，它就没必要这么做了——基于栈和基于寄存器的指令集只要经过合理的编译，得到的结果会是一模一样的。</p><p data-pid="IURVeO4d">至于LuaJIT，</p><p data-pid="PDJqrT7B">LuaJIT 1.x的字节码设计源于Lua 5.1.x系列，因而也是基于寄存器的；</p><p data-pid="K7AcFZZW">LuaJIT 2.x系列的字节码虽然重新设计了，但应该还是受到之前设计的影响而继续采用了基于寄存器的设计。像Mike Pall那种想榨干一切性能的思路，即便有优化的JIT编译器，也还是想让解释器尽量快的心情也是可以理解的。</p></span></div></span>



